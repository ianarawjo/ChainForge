{"flow": {"nodes": [{"width": 312, "height": 311, "id": "prompt-counterfactual-reasoning", "type": "prompt", "data": {"prompt": "{prompt}", "n": 1, "llms": [{"key": "aa3c0f03-22bd-416e-af4d-4bf5c4278c99", "settings": {"system_msg": "You are a helpful assistant.", "temperature": 1, "functions": [], "function_call": "", "top_p": 1, "stop": [], "presence_penalty": 0, "frequency_penalty": 0}, "name": "GPT3.5", "emoji": "\ud83d\ude42", "model": "gpt-3.5-turbo", "base_model": "gpt-3.5-turbo", "temp": 1, "formData": {"shortname": "GPT3.5", "model": "gpt-3.5-turbo", "system_msg": "You are a helpful assistant.", "temperature": 1, "functions": "", "function_call": "", "top_p": 1, "stop": "", "presence_penalty": 0, "frequency_penalty": 0}}]}, "position": {"x": 448, "y": 224}, "selected": false, "positionAbsolute": {"x": 448, "y": 224}, "dragging": false}, {"width": 333, "height": 182, "id": "eval-counterfactual-reasoning", "type": "evaluator", "data": {"code": "def evaluate(response):\n\ttxt = response.text\n\tideal = response.meta['Ideal']\n\treturn txt in ideal or ideal in txt"}, "position": {"x": 820, "y": 150}, "positionAbsolute": {"x": 820, "y": 150}}, {"width": 228, "height": 196, "id": "vis-counterfactual-reasoning", "type": "vis", "data": {"input": "eval-counterfactual-reasoning"}, "position": {"x": 1200, "y": 250}, "positionAbsolute": {"x": 1200, "y": 250}}, {"width": 302, "height": 260, "id": "inspect-counterfactual-reasoning", "type": "inspect", "data": {"input": "prompt-counterfactual-reasoning"}, "position": {"x": 820, "y": 400}, "positionAbsolute": {"x": 820, "y": 400}}, {"width": 423, "height": 417, "id": "table-counterfactual-reasoning", "type": "table", "data": {"rows": [{"prompt": "If the sky flies in a bird, then what does the ground run on?", "ideal": "human"}, {"prompt": "If a song sings a bird, then what does a book read?", "ideal": "human"}, {"prompt": "If the river swims in a fish, then what does a bone chew?", "ideal": "dog"}, {"prompt": "If the earth flows on the river, then what does the sky hangs in?", "ideal": "the sun"}, {"prompt": "If the windmill blows the wind, then what does the grass moisten?", "ideal": "the rain"}, {"prompt": "If the lock unlocks the key, then what does the sheath go in?", "ideal": "the knife or the sword"}, {"prompt": "If the moon means the day, then what does the sun means?", "ideal": "the night"}, {"prompt": "If the black color means bad things, then what does the white color means?", "ideal": "good things"}, {"prompt": "If the black color means a low position, then what does the white color means?", "ideal": "a high position"}, {"prompt": "If the ice feels hot, then what does the fire feel?", "ideal": "cold"}, {"prompt": "If the moon is bigger than the earth, then who is bigger between the earth and the sun?", "ideal": "the earth"}, {"prompt": "If the moon is a cubic object, then what is the shape of the sun?", "ideal": "cube"}, {"prompt": "If chinese food matches Beijing, then what does american food match?", "ideal": "washington"}, {"prompt": "If 1 is less than 2, then is 3 bigger than 4?", "ideal": "yes"}, {"prompt": "If one matches eno, then what does two match?", "ideal": "owt"}], "columns": [{"key": "prompt", "header": "Prompt"}, {"key": "ideal", "header": "Ideal"}]}, "position": {"x": -16, "y": 160}, "selected": false, "positionAbsolute": {"x": -16, "y": 160}, "dragging": false}], "edges": [{"source": "prompt-counterfactual-reasoning", "sourceHandle": "prompt", "target": "eval-counterfactual-reasoning", "targetHandle": "responseBatch", "interactionWidth": 100, "markerEnd": {"type": "arrow", "width": "22px", "height": "22px"}, "id": "reactflow__edge-prompt-1686756357355prompt-eval-1686756357355responseBatch"}, {"source": "prompt-counterfactual-reasoning", "sourceHandle": "prompt", "target": "inspect-counterfactual-reasoning", "targetHandle": "input", "interactionWidth": 100, "markerEnd": {"type": "arrow", "width": "22px", "height": "22px"}, "id": "reactflow__edge-prompt-1686756357355prompt-inspect-1686756357355input"}, {"source": "eval-counterfactual-reasoning", "sourceHandle": "output", "target": "vis-counterfactual-reasoning", "targetHandle": "input", "interactionWidth": 100, "markerEnd": {"type": "arrow", "width": "22px", "height": "22px"}, "id": "reactflow__edge-eval-1686756357355output-vis-1686756357355input"}, {"source": "table-counterfactual-reasoning", "sourceHandle": "Prompt", "target": "prompt-counterfactual-reasoning", "targetHandle": "prompt", "interactionWidth": 100, "markerEnd": {"type": "arrow", "width": "22px", "height": "22px"}, "id": "reactflow__edge-table-1686756385002Prompt-prompt-1686756357355prompt"}], "viewport": {"x": 144, "y": 37, "zoom": 1}}, "cache": {"eval-1686756357355.json": {}, "inspect-1686756357355.json": {}, "prompt-1686756357355.json": {}, "table-1686756385002.json": {}, "vis-1686756357355.json": {}}}